{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from libs.ds_charts import get_variable_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped variables []\n",
      "(161631, 32)\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = pd.read_csv('dataset_2/air_quality_tabular.csv', na_values='NaN')\n",
    "new_dataset_2 = dataset_2.copy()\n",
    "\n",
    "#FIND VARIABLES WITH MISSING VALUES\n",
    "mv = {}\n",
    "for var in new_dataset_2:\n",
    "    nr = new_dataset_2[var].isna().sum()\n",
    "    if nr > 0:\n",
    "        mv[var] = nr\n",
    "\n",
    "#DISCARD COLUMNS WITH MORE THEN 90% MISSING VALUES\n",
    "threshold = new_dataset_2.shape[0] * 0.90\n",
    "\n",
    "missings = [c for c in mv.keys() if mv[c]>threshold]\n",
    "new_dataset_2.drop(columns=missings, inplace=True)\n",
    "print('Dropped variables', missings)\n",
    "\n",
    "#DISCARD RECORDS WITH MAJORITY OF MISSING VALUES\n",
    "threshold = new_dataset_2.shape[1] * 0.50\n",
    "\n",
    "new_dataset_2.dropna(thresh=threshold, inplace=True)\n",
    "print(new_dataset_2.shape)\n",
    "\n",
    "for column in mv:\n",
    "    if column != \"Field_1\":\n",
    "        vars = dataset_2[column]\n",
    "        mean_vars = int(vars.mean())\n",
    "        dataset_2[column].fillna(mean_vars,inplace=True)\n",
    "    # else: # VER FIELD_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City_EN_Abacangzuqiangzu</th>\n",
       "      <th>City_EN_Akesudiqu</th>\n",
       "      <th>City_EN_Alashan</th>\n",
       "      <th>City_EN_Aletaidiqu</th>\n",
       "      <th>City_EN_Alidiqu</th>\n",
       "      <th>City_EN_Ankang</th>\n",
       "      <th>City_EN_Anqing</th>\n",
       "      <th>City_EN_Anshan</th>\n",
       "      <th>City_EN_Anshun</th>\n",
       "      <th>City_EN_Anyang</th>\n",
       "      <th>...</th>\n",
       "      <th>Prov_EN_Shaanxi</th>\n",
       "      <th>Prov_EN_Shandong</th>\n",
       "      <th>Prov_EN_Shanghai</th>\n",
       "      <th>Prov_EN_Shanxi</th>\n",
       "      <th>Prov_EN_Sichuan</th>\n",
       "      <th>Prov_EN_Tianjin</th>\n",
       "      <th>Prov_EN_Xinjiang</th>\n",
       "      <th>Prov_EN_Xizang</th>\n",
       "      <th>Prov_EN_Yunnan</th>\n",
       "      <th>Prov_EN_Zhejiang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>...</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "      <td>161631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>161265</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>161182</td>\n",
       "      <td>...</td>\n",
       "      <td>157141</td>\n",
       "      <td>149151</td>\n",
       "      <td>161182</td>\n",
       "      <td>156692</td>\n",
       "      <td>152451</td>\n",
       "      <td>161182</td>\n",
       "      <td>154878</td>\n",
       "      <td>158489</td>\n",
       "      <td>154450</td>\n",
       "      <td>155016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       City_EN_Abacangzuqiangzu City_EN_Akesudiqu City_EN_Alashan  \\\n",
       "count                    161631            161631          161631   \n",
       "unique                        2                 2               2   \n",
       "top                       False             False           False   \n",
       "freq                     161265            161182          161182   \n",
       "\n",
       "       City_EN_Aletaidiqu City_EN_Alidiqu City_EN_Ankang City_EN_Anqing  \\\n",
       "count              161631          161631         161631         161631   \n",
       "unique                  2               2              2              2   \n",
       "top                 False           False          False          False   \n",
       "freq               161182          161182         161182         161182   \n",
       "\n",
       "       City_EN_Anshan City_EN_Anshun City_EN_Anyang  ... Prov_EN_Shaanxi  \\\n",
       "count          161631         161631         161631  ...          161631   \n",
       "unique              2              2              2  ...               2   \n",
       "top             False          False          False  ...           False   \n",
       "freq           161182         161182         161182  ...          157141   \n",
       "\n",
       "       Prov_EN_Shandong Prov_EN_Shanghai Prov_EN_Shanxi Prov_EN_Sichuan  \\\n",
       "count            161631           161631         161631          161631   \n",
       "unique                2                2              2               2   \n",
       "top               False            False          False           False   \n",
       "freq             149151           161182         156692          152451   \n",
       "\n",
       "       Prov_EN_Tianjin Prov_EN_Xinjiang Prov_EN_Xizang Prov_EN_Yunnan  \\\n",
       "count           161631           161631         161631         161631   \n",
       "unique               2                2              2              2   \n",
       "top              False            False          False          False   \n",
       "freq            161182           154878         158489         154450   \n",
       "\n",
       "       Prov_EN_Zhejiang  \n",
       "count            161631  \n",
       "unique                2  \n",
       "top               False  \n",
       "freq             155016  \n",
       "\n",
       "[4 rows x 392 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'air_quality'\n",
    "filename = 'data/air_quality.csv'\n",
    "symbolic_vars = ['City_EN', 'Prov_EN']\n",
    "\n",
    "def dummify(df, vars_to_dummify):\n",
    "    other_vars = [c for c in df.columns if not c in vars_to_dummify]\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False, dtype=bool)\n",
    "    X = df[vars_to_dummify]\n",
    "    encoder.fit(X)\n",
    "    new_vars = encoder.get_feature_names(vars_to_dummify)\n",
    "    trans_X = encoder.transform(X)\n",
    "    dummy = pd.DataFrame(trans_X, columns=new_vars, index=X.index)\n",
    "    dummy = dummy.convert_dtypes(convert_boolean=True)\n",
    "\n",
    "    final_df = pd.concat([df[other_vars], dummy], axis=1)\n",
    "    return final_df\n",
    "\n",
    "variables = get_variable_types(new_dataset_2)\n",
    "df = dummify(new_dataset_2, symbolic_vars)\n",
    "df.to_csv(f'data/{file}_dummified.csv', index=False)\n",
    "\n",
    "df.describe(include=[bool])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "745d310d6c0ae55e49257fa2b34a349fe5a18b8d8dfaac89e4989c686accf5f0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('envComputerScience': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
